{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bcbde03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "284c6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.boston_housing.load_data(test_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "254be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, ytrain = train\n",
    "xtest, ytest = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1a04a873",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrains = tf.convert_to_tensor(StandardScaler().fit_transform(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e400b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.feature = xtrain.shape[1]\n",
    "        self.n_feature_ = self.feature\n",
    "        self.w = tf.Variable(tf.random.normal(shape=(self.feature, 1), dtype=tf.float64), name=\"weights\")\n",
    "        self.b = tf.Variable(tf.random.normal(shape=(1,), dtype=tf.float64), name=\"bias\")\n",
    "\n",
    "\n",
    "    def fit(self, iteration=1000, learning_rate=0.01):\n",
    "        self.optimizers = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "        for i in range(iteration):\n",
    "            with tf.GradientTape() as g:\n",
    "                ypred = tf.add(tf.matmul(self.x, self.w), self.b)\n",
    "                loss = self.rmse(self.y, ypred)\n",
    "            if i%100 == 0:\n",
    "                print(f\"epoch: {i}, loss: {loss}\")\n",
    "            dw, db = g.gradient(loss, [self.w, self.b])\n",
    "            #self.w.assign_sub(learning_rate*dw)\n",
    "            #self.b.assign_sub(learning_rate*db)\n",
    "            self.optimizers.apply_gradients(zip([dw, db], [self.w, self.b]))\n",
    "            \n",
    "    @tf.function\n",
    "    def rmse(self, ytrue, ypred):\n",
    "        return tf.reduce_mean(tf.square(tf.subtract(ytrue, ypred)))\n",
    "\n",
    "\n",
    "    def predict(self, x, y):\n",
    "        pred = tf.matmul(x, self.w) + self.b\n",
    "        return pred                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2086ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 587.1971836831113\n",
      "epoch: 100, loss: 533.9175646852481\n",
      "epoch: 200, loss: 492.38804585304376\n",
      "epoch: 300, loss: 454.76954666737987\n",
      "epoch: 400, loss: 419.93426390120135\n",
      "epoch: 500, loss: 387.61730739996403\n",
      "epoch: 600, loss: 357.6680905263211\n",
      "epoch: 700, loss: 329.96201609634005\n",
      "epoch: 800, loss: 304.38416584766026\n",
      "epoch: 900, loss: 280.8249632597633\n"
     ]
    }
   ],
   "source": [
    "sl = SimpleLinear(xtrains, ytrain)\n",
    "sl.fit(iteration=1000, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39397fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229206a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
